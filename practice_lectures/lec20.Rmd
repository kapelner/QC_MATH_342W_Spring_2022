---
title: "Practice Lecture 20 MATH 342W Queens College"
author: "Professor Adam Kapelner"
date: "April 19, 2021"
---



# Wide and Long Dataframe Formats

We will demonstrate a new concept on the dataset from lab #8: storms.

```{r}
pacman::p_load(data.table, tidyverse, magrittr)
summary(storms)
head(storms)
```

Let's first create a few variables that are of interest:

```{r}
storms %<>% 
  mutate(wind_pct_avg = wind / mean(wind, na.rm = TRUE) * 100) %>%
  mutate(pressure_pct_avg = pressure / mean(pressure, na.rm = TRUE) * 100) %>%
  mutate(ts_diameter_pct_avg = ts_diameter / mean(ts_diameter, na.rm = TRUE) * 100) %>%
  mutate(hu_diameter_pct_avg = hu_diameter / mean(hu_diameter, na.rm = TRUE) * 100)
ggplot(storms) + 
  aes(wind_pct_avg) + 
  geom_histogram()
```

Now let's take a look at these four variables we created for a storm we all remember and create a time period variable. I'll also instantiate a data.table object for later:

```{r}
sandy_wide_tbl = storms %>% 
  filter(name == "Sandy") %>%
  select(wind_pct_avg, pressure_pct_avg, ts_diameter_pct_avg, hu_diameter_pct_avg) %>% #we only care about our variables
  mutate(period = 1 : n()) %>%
  select(period, everything()) #reorder
sandy_wide_dt = data.table(sandy_wide_tbl)
sandy_wide_dt
```

This is called a "repeated measures" dataset or a "time series" and it is one of the most common data frame types. Unfortunately, we didn't have enough classtime to do a unit on time series. It really deserves its own class!

Regardless, it would be nice to be able to visualize It would be nice to look at the four variables we just created by time period. We can do this below:

```{r}
ggplot(sandy_wide_tbl) + 
  aes(x = period) + 
  geom_line(aes(y = wind_pct_avg), col = "red") + 
  geom_line(aes(y = pressure_pct_avg), col = "green") + 
  geom_line(aes(y = ts_diameter_pct_avg), col = "blue") + 
  geom_line(aes(y = hu_diameter_pct_avg), col = "grey") +
  #make legend code
  ylab("% over average")
```

Notice how that was a lot of lines of code which aren't so maintainable and we don't have a legend. Legends are built automatically in `ggplot2` when we set color to a variable. This means we somehow have to let the four variables we care about be there own categorical variable.

First note that the dataframe we have is in what's called "wide format" or "unstacked" meaning each row is an observation and the columns are its features. This is exactly the format of dataframe that we've been studying in this class. This is the format we humans prefer to read and it is the format for many important analyses and the format for modeling.

However, to get what we want above involves a "reshaping" our dataframe into another canonical form, one that is easier for machines to read, a format called "long format" or "narrow" or "stacked" which looks like this:

| Period      | Value       | variable     |
| ----------- | ----------- | -------------|
| 1           | 56.08       | wind_pct_avg |
| 2           | 65.43       | wind_pct_avg |
etc.

Sometimes this format is required for situations, so we should get used to "pivoting" between the two formats. 

We first go from wide to long. To do so, we identify the "id variables" which get their own row per category and the measurement variables which get their own entire subdataframe.

```{r}
sandy_long_tbl = pivot_longer(
  sandy_wide_tbl, 
  cols = -period, #measurement variables: all column except period and period is then the ID variable
  names_to = "metric", #default is "name"
  values_to = "val" #default is "value"
)
sandy_long_dt = melt(
  sandy_wide_dt,
  id.vars = "period",
  measure.vars = c("wind_pct_avg", "pressure_pct_avg", "ts_diameter_pct_avg", "hu_diameter_pct_avg"),
  variable.name = "metric",
  value.name = "val"
)
sandy_long_tbl
sandy_long_dt
```

Same output but note the difference in sorting: `tidyverse` sorts on the id variables first and `data.table` sorts on the measurements i.e. cbinding the subdataframes.

Now that it's in long format, the visualization code becomes very simple:

```{r}
ggplot(sandy_long_dt) +
  geom_line(aes(x = period, y = val, color = metric)) +
  ylab("% over average")
```

Now we go from long to wide:

```{r}
sandy_wide_tbl2 = pivot_wider(
  sandy_long_tbl,
  id_cols = period, 
  names_from = metric,
  values_from = val
)
sandy_wide_dt2 = dcast(
  sandy_long_dt,
  period ~ metric, #lhs is id and rhs is measurement variables
  value.var = "val" #the function can guess "val" has to be the cell values so it's not needed
)
sandy_wide_tbl2
sandy_wide_dt2
```

Who's faster?

```{r}
pacman::p_load(microbenchmark)
microbenchmark(
  wide_to_long_tidy = pivot_longer(
    sandy_wide_tbl, 
    cols = -period,
    names_to = "metric",
    values_to = "val"
  ),
  wide_to_long_dt = melt(
    sandy_wide_dt,
    id.vars = "period",
    measure.vars = c("wind_pct_avg", "pressure_pct_avg", "ts_diameter_pct_avg", "hu_diameter_pct_avg"),
    variable.name = "metric",
    value.name = "val"
  ),
  long_to_wide_tidy = pivot_wider(
    sandy_long_tbl,
    id_cols = period, 
    names_from = metric,
    values_from = val
  ),
  long_to_wide_dt = dcast(
    sandy_long_dt,
    period ~ metric,
    value.var = "val"
  ),
  times = 50
)
```

Looks like ``data.table::melt`` is 60x faster than tidyverse's pivot and ``data.tabe::dcast` is 2x faster than tidyverse's pivot.
